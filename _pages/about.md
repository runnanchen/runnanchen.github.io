---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently a postdoctoral researcher at the University of Sydney, under the supervision of [Prof Tongliang Liu](https://tongliang-liu.github.io/). Prior to that, I received my PhD from the Department of Computer Science at the University of Hong Kong in 2023, under the supervision of [Prof Wenping Wang](https://www.cs.hku.hk/people/academic-staff/wenping). 

My research interest is in 3D spatial intelligence, focusing on how intelligent agents can reconstruct, generate, perceive, reason, and interact in the 3D world, supporting core applications such as autonomous driving, robotics, AR/VR, and smart healthcare.


# üî• News
- *2025.06*: &nbsp; üéâ One papers is accepted by MICCAI.
- *2025.05*: &nbsp; üéâ One papers is accepted by TVCG.
- *2025.05*: &nbsp; üéâ One papers is accepted by ICML.
- *2025.02*: &nbsp; üéâ One papers is accepted by CVPR.
- *2024.07*: &nbsp; üéâ One paper is accepted by ECCV.
- *2024.02*: &nbsp; üéâ Four papers are accepted by CVPR.
- *2023.09*: &nbsp; üéâ Two papers are accepted by NeurIPS. 
- *2023.07*: &nbsp; üéâ One paper is accepted by ACM MM. 
- *2023.07*: &nbsp; üéâ Five papers are accepted by ICCV. 
- *2023.02*: &nbsp; üéâ One paper is accepted by CVPR. 

# üìù Selected Publications 



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2025</div><img src='images/LaVin-DiT.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Lavin-dit: Large vision diffusion transformer](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_LaVin-DiT_Large_Vision_Diffusion_Transformer_CVPR_2025_paper.pdf)

Zhaoqing Wang, Xiaobo Xia, **Runnan Chen**, Dongdong Yu, Changhu Wang, Mingming Gong, Tongliang Liu.
CVPR, 2025
[\[Project Page\]](https://derrickwang005.github.io/LaVin-DiT)
[\[Paper\]](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_LaVin-DiT_Large_Vision_Diffusion_Transformer_CVPR_2025_paper.pdf)
[\[Code\]](https://github.com/DerrickWang005/LaVin-DiT)
</div>
</div>





<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2025</div><img src='images/Non-Transferable.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">


[When Data-Free Knowledge Distillation Meets Non-Transferable Teacher: Escaping Out-of-Distribution Trap is All You Need](https://arxiv.org/pdf/2507.04119?)

Ziming Hong, **Runnan Chen**, Zengmao Wang, Bo Han, Bo Du, Tongliang Liu.
ICML, 2025
[\[Paper\]](https://arxiv.org/pdf/2507.04119?)
[\[Code\]](https://github.com/tmllab/2025_ICML_ATEsc)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv 2025</div><img src='images/surprise3D.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[SURPRISE3D: A Dataset for Spatial Understanding and Reasoning in Complex 3D Scenes](https://arxiv.org/pdf/2507.07781)

Jiaxin Huang, Ziwen Li, Hanlve Zhang, **Runnan Chen**, Xiao He, Yandong Guo, Wenping Wang, Tongliang Liu, Mingming Gong.
arXiv, 2025
[\[Paper\]](https://arxiv.org/pdf/2507.07781)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv 2024</div><video src='images/OVGaussian_demo.mp4' autoplay="autoplay" width="100%"></video></div></div>
<div class='paper-box-text' markdown="1">

[OVGaussian: Generalizable 3D Gaussian Segmentation with Open Vocabularies](https://arxiv.org/pdf/2501.00326)

**Runnan Chen**, Xiangyu Sun, Zhaoqing Wang, Youquan Liu, Jiepeng Wang, Lingdong Kong, Jiankang Deng, Mingming Gong, Liang Pan, Wenping Wang, Tongliang Liu.
arXiv, 2024
[\[Paper\]](https://arxiv.org/pdf/2501.00326)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv 2024</div><img src='images/panoslam.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Panoslam: Panoptic 3d scene reconstruction via gaussian slam](https://arxiv.org/pdf/2501.00352)

**Runnan Chen**, Zhaoqing Wang, Jiepeng Wang, Yuexin Ma, Mingming Gong, Wenping Wang, Tongliang Liu.
arXiv, 2024
[\[Paper\]](https://arxiv.org/pdf/2501.00352)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/M3Net.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Multispace alignments towards universal lidar segmentation](https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_Multi-Space_Alignments_Towards_Universal_LiDAR_Segmentation_CVPR_2024_paper.pdf)

Youquan Liu, Lingdong Kong, Xiaoyang Wu, **Runnan Chen**, Xin Li, Liang Pan, Ziwei Liu, Yuexin Ma.
CVPR, 2024
[\[Paper\]](https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_Multi-Space_Alignments_Towards_Universal_LiDAR_Segmentation_CVPR_2024_paper.pdf)
[\[Code\]](https://github.com/youquanl/M3Net)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/IS-Fusion.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[IS-FUSION: Instance-scene Collaborative Fusion for Multimodal 3D Object Detection](https://openaccess.thecvf.com/content/CVPR2024/papers/Yin_IS-Fusion_Instance-Scene_Collaborative_Fusion_for_Multimodal_3D_Object_Detection_CVPR_2024_paper.pdf)

Junbo Yin, Jianbing Shen, **Runnan Chen**, Wei Li, Ruigang Yang, Pascal Frossard, Wenguan Wang.
CVPR, 2024
[\[Paper\]](https://openaccess.thecvf.com/content/CVPR2024/papers/Yin_IS-Fusion_Instance-Scene_Collaborative_Fusion_for_Multimodal_3D_Object_Detection_CVPR_2024_paper.pdf)
[\[Code\]](https://github.com/yinjunbo/IS-Fusion)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2023</div><img src='images/clip2scene_f.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[CLIP2Scene: Towards Label-efficient 3D Scene Understanding by CLIP](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_CLIP2Scene_Towards_Label-Efficient_3D_Scene_Understanding_by_CLIP_CVPR_2023_paper.pdf)

**Runnan Chen**, Youquan Liu, Lingdong Kong, Xinge Zhu, Yuexin Ma, Yikang Li, Yuenan Hou, Yu Qiao, Wenping Wang.
CVPR, 2023
[\[paper\]](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_CLIP2Scene_Towards_Label-Efficient_3D_Scene_Understanding_by_CLIP_CVPR_2023_paper.pdf)
[\[Code\]](https://github.com/runnanchen/CLIP2Scene)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM 2023</div><img src='images/zero_3d.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Bridging Language and Geometric Primitives for Zero-shot Point Cloud Segmentation](https://dl.acm.org/doi/pdf/10.1145/3581783.3612409)

**Runnan Chen**, Xinge Zhu, Nenglun Chen, Wei Li, Yuexin Ma, Ruigang Yang, Wenping Wang.
ACM MM, 2023
[\[paper\]](https://dl.acm.org/doi/pdf/10.1145/3581783.3612409)
[\[Code\]](https://github.com/runnanchen/Zero-Shot-Point-Cloud-Segmentation)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2023</div><img src='images/robo3d.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Robo3d: Towards robust and reliable 3d perception against corruptions](https://openaccess.thecvf.com/content/ICCV2023/papers/Kong_Robo3D_Towards_Robust_and_Reliable_3D_Perception_against_Corruptions_ICCV_2023_paper.pdf)

Lingdong Kong, Youquan Liu, Xin Li, **Runnan Chen**, Wenwei Zhang, Jiawei Ren, Liang Pan, Kai Chen, Ziwei Liu.
ICCV, 2023
[\[paper\]](https://openaccess.thecvf.com/content/ICCV2023/papers/Kong_Robo3D_Towards_Robust_and_Reliable_3D_Perception_against_Corruptions_ICCV_2023_paper.pdf)
[\[Code\]](https://github.com/ldkong1205/Robo3D)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2023</div><img src='images/seal.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Segment Any Point Cloud Sequences by Distilling Vision Foundation Models](https://proceedings.neurips.cc/paper_files/paper/2023/file/753d9584b57ba01a10482f1ea7734a89-Paper-Conference.pdf)

Youquan Liu, Lingdong Kong, Jun Cen, **Runnan Chen**, Wenwei Zhang, Liang Pan, Kai Chen, Ziwei Liu.
NeurIPS, 2023
[\[paper\]](https://proceedings.neurips.cc/paper_files/paper/2023/file/753d9584b57ba01a10482f1ea7734a89-Paper-Conference.pdf)
[\[Code\]](https://github.com/youquanl/Segment-Any-Point-Cloud)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2023</div><img src='images/free3d.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Towards label-free scene understanding by vision foundation models](https://proceedings.neurips.cc/paper_files/paper/2023/file/ef6c94e9cf4d169298479ee2e230ee13-Paper-Conference.pdf)

**Runnan Chen**, Youquan Liu, Lingdong Kong, Nenglun Chen, Xinge Zhu, Yuexin Ma, Tongliang Liu, Wenping Wang.
NeurIPS, 2023
[\[paper\]](https://proceedings.neurips.cc/paper_files/paper/2023/file/ef6c94e9cf4d169298479ee2e230ee13-Paper-Conference.pdf)
[\[Code\]](https://github.com/runnanchen/Label-Free-Scene-Understanding)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TMI 2022</div><img src='images/SA-LSTM.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Structure-aware long short-term memory network for 3d cephalometric landmark detection
](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9705609)

**Runnan Chen**, Yuexin Ma, Nenglun Chen, Lingjie Liu, Zhiming Cui, Yanhong Lin, Wenping Wang.
TMI, 2022
[\[paper\]](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9705609)
[\[Code\]](https://github.com/runnanchen/SA-LSTM-3D-Landmark-Detection)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2021</div><img src='images/PR-Net.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Pr-net: Preference reasoning for personalized video highlight detection](https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_PR-Net_Preference_Reasoning_for_Personalized_Video_Highlight_Detection_ICCV_2021_paper.pdf)

**Runnan Chen**, Penghao Zhou, Wenzhe Wang, Nenglun Chen, Pai Peng, Xing Sun, Wenping Wang.
ICCV, 2021
[\[paper\]](https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_PR-Net_Preference_Reasoning_for_Personalized_Video_Highlight_Detection_ICCV_2021_paper.pdf)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">MICCAI 2019</div><img src='images/AFPF.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Cephalometric landmark detection by attentive feature pyramid fusion and regression-voting](https://arxiv.org/pdf/1908.08841)

**Runnan Chen**, Yuexin Ma, Nenglun Chen, Daniel Lee, Wenping Wang.
MICCAI, 2019
[\[paper\]](https://arxiv.org/pdf/1908.08841)
[\[Code\]](https://github.com/runnanchen/Anatomic-Landmark-Detection)
</div>
</div>

#  Academic Services
- Journal reviewers: TPAMI, IJCV, TMI, TIP.
- Regular conference reviewers/program committee: NeurIPS, SIGGRAPH, CVPR, ICML, ICLR, ICCV, ECCV, AAAI, IJCAI, ACM MM, MICCAI. 


# üéñ Honors and Awards
- *2017-2021* Postgraduate Scholarship of HKU.
- *2013* National Scholarship. 
- *2012* Liaoning Government Scholarship. 

